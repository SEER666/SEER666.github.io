<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>SEER&#39;s Study</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Record SEER&#39;s learning content.">
<meta property="og:type" content="website">
<meta property="og:title" content="SEER&#39;s Study">
<meta property="og:url" content="https://seer666.github.io/index.html">
<meta property="og:site_name" content="SEER&#39;s Study">
<meta property="og:description" content="Record SEER&#39;s learning content.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="[object Object]">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="SEER's Study" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SEER&#39;s Study</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">SEER</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://SEER666.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-20241028" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/28/20241028/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T09:15:00.000Z" itemprop="datePublished">2024-10-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/28/20241028/">20241028-CSAPP课本阅读</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="第1章-计算机系统漫游"><a href="#第1章-计算机系统漫游" class="headerlink" title="第1章 计算机系统漫游"></a>第1章 计算机系统漫游</h1><p>计算机系统：硬件和系统软件组成</p>
<h2 id="1-1-信息就是位-上下文"><a href="#1-1-信息就是位-上下文" class="headerlink" title="1.1 信息就是位+上下文"></a>1.1 信息就是位+上下文</h2><p>程序的生命周期：始于源程序（源文件）；<br>源程序：由值0和1组成的位（又称比特）序列；<br>字节：8个位被组织成一组；<br>文本文件：只由ASCII字符构成；  二进制文件：所有其他非“文本文件”的文件为二进制文件；</p>
<h2 id="1-2-程序被其他程序翻译成不同的格式"><a href="#1-2-程序被其他程序翻译成不同的格式" class="headerlink" title="1.2 程序被其他程序翻译成不同的格式"></a>1.2 程序被其他程序翻译成不同的格式</h2><p>C语句都被徐被其他程序转化为一系列的低级机器语言指令，然后这些指令按照一种称为可执行目标程序的格式打好包。<br>编译系统：预处理器、编译器、汇编器、连接器<br>预处理阶段：根据#开头的命令，修改原始的C程序。<br>编译阶段：将文本文件.i翻译成文本文件.s，包含一个汇编语言程序。<br>汇编阶段：汇编器将文本文件.s翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在目标文件.o中。<br>链接阶段：链接器将其他函数（例如printf函数）所在的单独预编译目标文件.o与主.o文件合并。</p>
<h2 id="1-3-了解编译系统如何工作是大有益处的"><a href="#1-3-了解编译系统如何工作是大有益处的" class="headerlink" title="1.3 了解编译系统如何工作是大有益处的"></a>1.3 了解编译系统如何工作是大有益处的</h2><p>优化程序性能、理解链接时出现的错误、避免安全漏洞</p>
<h2 id="1-4-处理器读并解释储存在内存中的指令"><a href="#1-4-处理器读并解释储存在内存中的指令" class="headerlink" title="1.4 处理器读并解释储存在内存中的指令"></a>1.4 处理器读并解释储存在内存中的指令</h2><p>shell应用程序运行可执行文件（Unix系统）。输出一个提示符，等待输入一个命令行，然后执行这个命令。<br>若第一个单词不是内置shell命令，那么会假设这是一个可执行文件的名字，然后等待程序终止。</p>
<h3 id="1-4-1-系统的硬件组成"><a href="#1-4-1-系统的硬件组成" class="headerlink" title="1.4.1 系统的硬件组成"></a>1.4.1 系统的硬件组成</h3><p>总线：贯穿整个系统的一组电子管道，被设计为传送定长的字节块；<br>I&#x2F;O设备：系统与外部世界的联系通道，示例系统包括作为用户输入的键盘和鼠标、作为用户输出的显示器、用于长期存储数据和程序的磁盘驱动器。<br>相关的硬件组成如本图：通过百度网盘分享的文件：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1yZan2Lg3RvQHPMsRertFDQ">百度网盘分享，提取码：7568</a><br>主存：临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上说，主存是由一组动态随机存取存储器芯片组成的；从逻辑上来说，存储器是一个现行的字节数组，每个字节都有其唯一的地址，这些地址是从零开始。<br>处理器：中央处理单元（CPU），是解释（或执行）存储在主存中指令的引擎，处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计算器（PC）。在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）。<br>处理器可能会执行的操作：加载，从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容；存储，从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容；操作，吧两个寄存器的内容复制到ALU，ALU对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容；跳转，从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，以覆盖PC中原来的值。</p>
<h3 id="1-4-2-运行hello程序"><a href="#1-4-2-运行hello程序" class="headerlink" title="1.4.2 运行hello程序"></a>1.4.2 运行hello程序</h3><p>步骤如下：从键盘上读取hello命令，然后从磁盘加载可执行文件到内存，最后将输出字符串从存储器写到显示器。</p>
<h2 id="1-5-高速缓存至关重要"><a href="#1-5-高速缓存至关重要" class="headerlink" title="1.5 高速缓存至关重要"></a>1.5 高速缓存至关重要</h2><p>高速缓存存储器：针对这种处理器与主存之间的差异，系统设计者采用更小更快的存储设备，作为暂时的集结区域，存放处理器近期可能会需要的信息。</p>
<h2 id="1-6-存储设备形成层次结构"><a href="#1-6-存储设备形成层次结构" class="headerlink" title="1.6 存储设备形成层次结构"></a>1.6 存储设备形成层次结构</h2><p>层次结构如下：寄存器-&gt;L1高速缓存-&gt;L2高速缓存-&gt;L3高速缓存-&gt;主存-&gt;本地二级存储-&gt;远程二级存储。</p>
<h2 id="1-7-操作系统管理硬件"><a href="#1-7-操作系统管理硬件" class="headerlink" title="1.7 操作系统管理硬件"></a>1.7 操作系统管理硬件</h2><p>计算机系统分层：应用程序、操作系统——软件，处理器、主存、I&#x2F;O设备——硬件。<br>操作系统提供的抽象表示：文件-&gt;I&#x2F;O设备，虚拟内存-&gt;主存、I&#x2F;O设备，进程-&gt;处理器、主存、I&#x2F;O设备<br>操作系统的两个基本功能：防止硬件被失控的应用程序滥用；像应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。</p>
<h3 id="1-7-1-进程"><a href="#1-7-1-进程" class="headerlink" title="1.7.1 进程"></a>1.7.1 进程</h3><p>进程：操作系统对一个正在运行的程序的一种抽象，在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用软件。<br>并发运行：一个进程的指令和另一个进程的指令是交错执行的。</p>
<h3 id="1-7-2-线程"><a href="#1-7-2-线程" class="headerlink" title="1.7.2 线程"></a>1.7.2 线程</h3><p>线程与进程：一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。</p>
<h3 id="1-7-3-虚拟内存"><a href="#1-7-3-虚拟内存" class="headerlink" title="1.7.3 虚拟内存"></a>1.7.3 虚拟内存</h3><p>虚拟内存：为每个进程提供了一个假象，即每个进程都在独占地使用主存。<br>虚拟地址空间：每个进程看到的内存都是一致的。<br>过程如下：程序开始-&gt;只读的代码和数据-&gt;读&#x2F;写数据-&gt;运行时堆-&gt;共享库的内存映射区域-&gt;&lt;-用户栈（运行时创建的）&lt;-内核虚拟内存<br>各部分介绍如下：<br>程序代码和数据：代码从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。<br>堆：代码和数据区后紧随着的是运行时堆。（区分：代码和数据去在进程一开始运行时就被置顶了大小，而堆可以在运行时动态地扩展和收缩）<br>共享库：地址空间的中间部分是一块用来存放像C标准库或者数学库的共享代码和数据的区域。<br>栈：位于用户虚拟地址空间顶部的是用户栈，编译器用它赖实现函数调用。<br>内核虚拟内存：地址空间顶部的区域是为内核保留的，不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。</p>
<h3 id="1-7-4-文件"><a href="#1-7-4-文件" class="headerlink" title="1.7.4 文件"></a>1.7.4 文件</h3><p>文件就是字节序列。每个I&#x2F;O设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。</p>
<h2 id="1-8-系统之间利用网络通信"><a href="#1-8-系统之间利用网络通信" class="headerlink" title="1.8 系统之间利用网络通信"></a>1.8 系统之间利用网络通信</h2><p>网络也是一种I&#x2F;O设备，属于客户端和服务器之间的交互，流程与之前提及的类似。</p>
<h2 id="1-9-重要主题"><a href="#1-9-重要主题" class="headerlink" title="1.9 重要主题"></a>1.9 重要主题</h2><h3 id="1-9-1-Amdahl定律"><a href="#1-9-1-Amdahl定律" class="headerlink" title="1.9.1 Amdahl定律"></a>1.9.1 Amdahl定律</h3><p>该部分的相关公式与介绍如图<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1pjkidciZSMSOsHYhVemWBA">百度网盘分享，提取码：7568</a></p>
<h3 id="1-9-2-并发和并行"><a href="#1-9-2-并发和并行" class="headerlink" title="1.9.2 并发和并行"></a>1.9.2 并发和并行</h3><p>并发：一个同时具有多个活动的系统；<br>并行：用并发来使一个系统运行得更快。</p>
<p><strong>线程级并发</strong><br>概念：构建在进程这个抽象之上，我们能够设计出同时有多个程序执行的系统，这就导致了并发。<br>单处理器系统：即使处理器必须在多个任务间切换，大多数实际的计算也都是由一个处理器来完成的。<br>多处理器系统：由单操作系统内核控制的多处理器组成的系统。<br>多处理器系统的组织结构如图：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1kwNeB0sw5Pr5ZiGFLKQ4bw">百度网盘分享，提取码：7568</a><br>超线程（同时多线程），是一项允许一个CPU执行多个控制流的技术。</p>
<p><strong>指令级并行</strong><br>在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。<br>超标量处理器：处理器可以达到比一个周期一条指令更快的执行效率。</p>
<p><strong>单指令、多数据并行</strong><br>单指令、多数据“在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称位单指令、多数据，即SIMD并行。</p>
<h3 id="1-9-3-计算机系统中抽象的重要性"><a href="#1-9-3-计算机系统中抽象的重要性" class="headerlink" title="1.9.3 计算机系统中抽象的重要性"></a>1.9.3 计算机系统中抽象的重要性</h3><p>计算机系统提供的抽象如图：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1XmVDyQSbZkU8lQTc0D78RQ">百度网盘分享，提取码：7568</a></p>
<h2 id="第1章乐学习题"><a href="#第1章乐学习题" class="headerlink" title="第1章乐学习题"></a>第1章乐学习题</h2><p>1.以下说法正确的是（ D ）。<br>a.处理器顺序执行机器指令。<br>b.主存储器包括寄存器。<br>c.总线系统只用来传输数据，不传输指令。<br>d.中央处理器（CPU）是特定指令集架构下的执行单元。</p>
<p>2.可执行目标程序是（ B ）。<br>a.在目标机运行的汇编语言程序。<br>b.是机器指令被按照固定格式打包的二进制文件。<br>c.由编译器产生的汇编程序。<br>d.在目标机运行的高级语言程序。</p>
<p>3.SHELL的功能是（ A ）。<br>a.一个操作系统的命令行解释器。<br>b.只能接受系统命令。<br>c.一个操作系统。<br>d.不能运行可执行文件。</p>
<p>4.以下关于内存管理的说法错误的是： （ B ）<br>a.显式链表分配时间与空闲块的数量成线性关系<br>b.标记清除垃圾收集算法是由程序员手动编码调用触发的<br>c.隐式链表双向合并可以常量时间完成<br>d.分离链表的First-fit 搜索近似于整个堆上的best-fit搜索</p>
<p>5.可执行目标程序是（ A ）。<br>a.是机器指令被按照固定格式打包的二进制文件。<br>b.在目标机运行的高级语言程序。<br>c.由编译器产生的汇编程序。<br>d.在目标机运行的汇编语言程序。</p>
<p>6.有关存储的层次结构说法正确的是（ A ）。<br>a.从上至下访问速度下降，存储容量增大。<br>b.磁盘存储和主存的地址空间连续。<br>c.寄存器与高速缓存都是对程序员透明的。<br>d.高速缓存和主存具有相同硬件结构。</p>
<p>7.磁盘文件a.txt由10个ASCII码字符“chinagood!”组成，下列程序运行后输出为（ A ）。#include “csapp.h”int main(){int  fd1,fd2;char c; fd1&#x3D;open(“a.txt”,O_RDONLY,0); fd2&#x3D;open(“a.txt”,O_RDONLY,0);read (fd2,&amp;c,1);dup2(fd2,fd1);read (fd1,&amp;c,1);printf(“c&#x3D;%c\n”,c);exit(0);}<br>a.c&#x3D;h<br>b.c&#x3D;n<br>c.c&#x3D;i<br>d.c&#x3D;c</p>
<p>8.程序的生命周期是从（ B ）开始的。<br>a.代码运行开始。<br>b.被程序员创建开始。<br>c.安装在系统后开始。<br>d.编译成可执行文件开始。</p>
<p>9.程序运行性能的影响因素是：（  AB  ）<br>A.算法、编程语言、编译器、指令集体系结构<br>B.指令序列和CPI<br>C.硬件是核心因素<br>D.操作系统是核心因素</p>
<p>10.进程上下文切换是有（  BD  ）完成的。<br>A.用户代码和内核代码<br>B.操作系统<br>C.用户代码<br>D.内核代码</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/10/28/20241028/" data-id="cm2tuviet000cfw9ja8vyba58" data-title="20241028-CSAPP课本阅读" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CSAPP/" rel="tag">CSAPP</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-20241027" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/27/20241027/" class="article-date">
  <time class="dt-published" datetime="2024-10-27T08:00:00.000Z" itemprop="datePublished">2024-10-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/27/20241027/">20241027论文学习</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Communication-Efficient-and-Private-Federated-Learning-with-Adaptive-Sparsity-Based-Pruning-on-Edge-Computing（基于边缘计算的通信高效和私有自适应稀疏剪枝的联邦学习）"><a href="#Communication-Efficient-and-Private-Federated-Learning-with-Adaptive-Sparsity-Based-Pruning-on-Edge-Computing（基于边缘计算的通信高效和私有自适应稀疏剪枝的联邦学习）" class="headerlink" title="Communication-Efficient and Private Federated Learning with Adaptive Sparsity-Based Pruning on Edge Computing（基于边缘计算的通信高效和私有自适应稀疏剪枝的联邦学习）"></a>Communication-Efficient and Private Federated Learning with Adaptive Sparsity-Based Pruning on Edge Computing（基于边缘计算的通信高效和私有自适应稀疏剪枝的联邦学习）</h1><h1 id="论文摘要"><a href="#论文摘要" class="headerlink" title="论文摘要"></a>论文摘要</h1><p>随着数据驱动的深度学习（DL）被应用于多种场景，隐私威胁已成为广泛关注的问题。为增强联邦学习（FL）中的隐私保护，一些方法采用一次性差分隐私（DP）方法来模糊化模型更新，但并未考虑<strong>效率与隐私保护之间的动态平衡</strong>。为此，本文提出了一种基于自适应稀疏裁剪和差分隐私保护的高效联邦学习方法<strong>ASPFL</strong>。我们进一步提出使用<strong>Jensen-Shannon散度</strong>作为度量来生成稀疏矩阵，以用于模型更新。此外，通过评估剪枝后的敏感度变化，我们引入了<strong>自适应高斯噪声</strong>。广泛实验验证了ASPFL在非独立同分布数据条件下将收敛速度提升超过两倍。与现有的DP-FL方法相比，ASPFL在<strong>CIFAR-10数据集</strong>上最高可达到82%的精度，同时在相同隐私保护水平下通信成本减少了40%。</p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h1><p>深度神经网络（DNN）的快速发展，使其在计算机视觉（CV）和自然语言处理（NLP）等任务中得到广泛应用，深度学习逐渐演变成一种依赖大量训练数据的技术。近年来，对高效且具隐私保护的深度学习解决方案的需求越来越受到关注。联邦学习（FL）作为一种分布式机器学习的创新范式应运而生，与传统的将数据上传到云端训练的深度学习不同，联邦学习允许多个<strong>边缘设备</strong>在本地训练模型并上传模型更新。<br>然而，依赖本地私有样本的模型更新和客户端之间的大规模参数传输带来了显著的通信负担和隐私问题。在通信开销方面，研究表明大多数深度神经网络（DNN）存在<strong>过度参数化</strong>的情况。部分研究提出仅使用少量权重即可获得与全连接多层感知机（MLP）和卷积神经网络（CNN）相似的性能。进一步研究表明，在不显著降低性能的前提下，可以裁剪掉Transformers中的一部分头结构。可行的方案是通过<strong>模型压缩（例如裁剪和蒸馏）</strong>来减少参数传输，从而显著缩小模型规模并加快推理速度。<br>对于FL的隐私和安全问题，研究表明，<strong>客户端上传的敏感个人参数可能会通过模型反演攻击而泄露</strong>。因此，将差分隐私（DP）与FL结合被视为一种有效的隐私保护技术。DP的机制通常通过向中间输出添加随机噪声，确保特定输入元素的变化不会对输出分布产生显著影响。然而，在基于DP的FL中，<strong>模型效用和隐私保护水平</strong>之间存在不可避免的权衡。</p>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2.相关工作"></a>2.相关工作</h1><p>联邦学习（FL）是一种机器学习中的基础训练范式，最早于2016年提出。其目标是通过分布式数据集构建一个协作的机器学习模型。近年来，联邦学习面临着日益增长的挑战，包括通信开销、数据异质性和隐私威胁。本节将介绍差分隐私在联邦学习中的应用以及模型剪枝技术。</p>
<h2 id="2-1-联邦学习中的差分隐私"><a href="#2-1-联邦学习中的差分隐私" class="headerlink" title="2.1 联邦学习中的差分隐私"></a>2.1 联邦学习中的差分隐私</h2><p>差分隐私（DP）被广泛用于缓解联邦学习中的用户隐私泄露问题。差分隐私随机梯度下降（DP-SGD）提供了一种数据级别的隐私保证，可以通过向裁剪后的梯度添加高斯噪声轻松实现。然而，FL不仅关注本地数据的隐私保护，也需要保证客户端之间的信息安全。现有研究可分为两类：集中式差分隐私（CDP）和本地差分隐私（LDP）。LDP的核心思想是随机响应（RR）。在联邦学习中，LDP允许各方对数据进行混淆处理，然后将模糊化的数据发布给不可信的服务器。</p>
<h2 id="2-2-模型剪枝"><a href="#2-2-模型剪枝" class="headerlink" title="2.2 模型剪枝"></a>2.2 模型剪枝</h2><p>随着深度神经网络（DNN）的广泛应用，模型剪枝成为减少计算资源的重要课题。常用的方法是基于幅度的剪枝。Jiang等人基于“彩票假说”提出，通过对权重幅度进行剪枝可以得到原始网络的最佳子结构。<br>一般来说，剪枝方法可以分为结构化剪枝和非结构化剪枝两类。结构化剪枝通过删除网络内的结构单元（如卷积核、滤波器或层）来降低模型复杂度。这种方法通常需要特定的网络结构，与“彩票假说”不完全一致。此外，最优的剪枝率通常依赖于经验知识，且原始模型需要重新训练。Zhu等人提出了一种名为FedLP-Q的有效模型压缩和加速框架，通过分层剪枝和量化来实现。在该框架中，剪枝过程发生在模型的每一层，通过移除不重要的权重或层来减小模型的深度和宽度，但这会减少中间表示中的特征图数量。<br>相比之下，非结构化剪枝主要聚焦于单个权重层级的剪枝。在不改变网络原始结构的情况下，通过将不重要的权重置零实现稀疏性。Qian等人提出了一种动态调整策略，通过逐步增加稀疏率并将聚合权重替换为稀疏性的倒数来减少不必要的传输成本。然而，该方法没有考虑数据分布不均可能对聚合权重产生的影响。</p>
<h1 id="3-我们的方法：ASPFL-框架"><a href="#3-我们的方法：ASPFL-框架" class="headerlink" title="3.我们的方法：ASPFL 框架"></a>3.我们的方法：ASPFL 框架</h1><p>在本节中，我们提出了一个通用框架 ASPFL，介绍了基于自适应稀疏性裁剪的模块和中心差分隐私机制，并对剪枝后的模型进行了深入的隐私分析。论文中使用的符号在表 1 中进行了汇总。</p>
<h2 id="3-1-概述和问题陈述"><a href="#3-1-概述和问题陈述" class="headerlink" title="3.1 概述和问题陈述"></a>3.1 概述和问题陈述</h2><p><strong>工作流程</strong>：<br>我们提出的 ASPFL 工作流程包含五个阶段：<br>1.服务器首先初始化全局模型，并将其分发给客户端。<br>2.选定的客户端基于当前全局模型和各自的数据集训练本地模型。在本地训练中，客户端根据 L2 范数执行梯度裁剪以满足差分隐私 (DP) 要求。<br>3.完成 L 轮本地训练后，各客户端根据可学习的稀疏矩阵进行通道裁剪，并估计本地模型联合的敏感度。然后将本地模型更新上传至服务器。<br>4.服务器收集所有模型更新，并基于估计的敏感度引入自适应噪声以进行模型聚合。<br>5.最后获得一个新的全局模型。 </p>
<p><strong>系统模型</strong>：基于客户端&#x2F;服务器 (C&#x2F;S) 框架，基本的联邦学习 (FL) 系统由 N 个客户端和一个服务器组成，旨在在隐私保护的前提下协作训练一个最优模型。假设服务器“诚实但好奇”，每个客户端持有包含样本的本地数据集 ( D_i )，所有本地数据集的并集记为 ( D )。ASPFL 的目标是通过聚合来自 N 个客户端的本地模型，获得最小化全局经验风险的最优全局模型。</p>
<p><strong>威胁模型</strong>：假设服务器诚实但好奇，尽管 FL 使各客户端的数据集保持本地存储，但与服务器共享模型参数可能会暴露客户端的私有信息。这类攻击包括通过模型参数推测训练数据集或推断私有特征。每个客户端也可能被视为“诚实但好奇”，可能对其他客户端数据进行类似的隐私攻击。</p>
<h2 id="3-2-ASPFL算法"><a href="#3-2-ASPFL算法" class="headerlink" title="3.2 ASPFL算法"></a>3.2 ASPFL算法</h2><p>ASPFL 的工作流程包括以下 5 个步骤：</p>
<p>1.<strong>全局模型初始化</strong>：服务器首先初始化全局模型参数并将其分发给每个客户端。<br>2.<strong>本地模型更新</strong>：在每一轮全局训练中，随机选择 ( K ) 个客户端参与本地训练。通过梯度裁剪和自适应因子，控制更新幅度并更新本地模型。<br>3.<strong>基于稀疏性的通道裁剪</strong>：在第 ( t ) 轮训练中，每个客户端在完成本地训练后生成新的本地模型，并采用自适应稀疏矩阵去除不重要的模型更新。<br>4.<strong>模型聚合与噪声扰动</strong>：服务器收集所有参与客户端的模型更新，并添加高斯噪声来保护隐私。噪声的方差基于所需的隐私预算和敏感度计算。<br>5.<strong>全局模型广播</strong>：服务器将更新后的全局模型广播至所有客户端，开始新一轮的本地训练。</p>
<p>该算法的主要改进包括：(1) 在本地训练中累积梯度的缩放规则；(2) 基于稀疏矩阵的自适应通道裁剪；(3) 在服务器端剪枝后的噪声添加策略。</p>
<h2 id="3-3-基于自适应稀疏性的通道裁剪"><a href="#3-3-基于自适应稀疏性的通道裁剪" class="headerlink" title="3.3 基于自适应稀疏性的通道裁剪"></a>3.3 基于自适应稀疏性的通道裁剪</h2><p>为减少参数上传时对网络稳定性的依赖，ASPFL 通过可学习的门控参数实现模型的稀疏性。稀疏矩阵是根据门控参数生成的，表示“1”在矩阵中的占比。通过将该矩阵应用于模型参数，有效去除不重要的系数，从而减少带宽需求，同时减轻模型反演或成员推断攻击的潜在风险。</p>
<h2 id="3-4-剪枝后的隐私保证"><a href="#3-4-剪枝后的隐私保证" class="headerlink" title="3.4 剪枝后的隐私保证"></a>3.4 剪枝后的隐私保证</h2><p>为应对参与方的隐私和安全问题，我们在服务器的聚合阶段引入高斯机制以实现 DP。DP 的高斯机制具有可量化的隐私预算和隐蔽用户行为的优势。</p>
<h1 id="4-结果与讨论"><a href="#4-结果与讨论" class="headerlink" title="4.结果与讨论"></a>4.结果与讨论</h1><p>本文在 CIFAR-10 和 Fashion-MNIST 数据集上进行了一些实验，以评估所提出的 ASPFL 算法的性能。</p>
<h2 id="4-1-实验设置"><a href="#4-1-实验设置" class="headerlink" title="4.1 实验设置"></a>4.1 实验设置</h2><p>实验在一台配置了 AMD Ryzen 5 5600 六核处理器和 16 GB 内存的计算机上进行，并配备了 16 GB 显存的 NVIDIA GeForce RTX 3070 显卡。训练集和测试集的比例为 8:2。模型性能在非独立同分布（non-IID）数据下进行测量，使用 Dirichlet（α）参数模拟不同客户端间数据集的分布，通过调整 α 控制 non-IID 程度（α 越大，数据分布越接近独立同分布）。在边缘设备上部署模型时，我们选择 ResNet18 作为骨干模型，联邦学习系统中客户端数量 N &#x3D; 10，具有不同的参与比例。初始学习率设置为 0.01，本地训练的轮数 L 固定为 3，局部梯度裁剪的阈值 C 设为 1，差分隐私预算 ε 设置为 2.0，δ &#x3D; 10⁻⁵，全局迭代次数上限为 200。</p>
<h2 id="4-2-剪枝性能比较"><a href="#4-2-剪枝性能比较" class="headerlink" title="4.2 剪枝性能比较"></a>4.2 剪枝性能比较</h2><p>首先，在未引入差分隐私（DP）噪声的情况下，评估 ASPFL 中剪枝模块的性能，记为 ASPFL-p。在 Dirichlet 非独立同分布数据下，α 设置为 0.5、0.7、1 和 10。结果表明，当 α &#x3D; 0.5 时，客户端间子数据集的分布呈现出极端不均衡和标签偏差，这导致一些类别的样本数量非常高，而某些类别完全没有样本，形成了偏斜分布。</p>
<p>在 Figures 4 和 5 中显示了 ASPFL-p 与原始 FedAvg 和 FedLP 的准确性和收敛速度的比较。例如，在 α &#x3D; 0.5 的数据分布高度不平衡的情况下，ASPFL-p 的准确性曲线更平滑，收敛速度更快，且无显著波动。这表明即使面对高度不平衡的数据分布，算法仍然保持稳定的训练性能。该现象可归因于算法中引入的累积梯度的 L2 范数裁剪，这有助于减少模型更新的波动，提高在非独立同分布数据集上的收敛稳定性。</p>
<h2 id="4-3-隐私性能比较"><a href="#4-3-隐私性能比较" class="headerlink" title="4.3 隐私性能比较"></a>4.3 隐私性能比较</h2><p>在 IID 和 Dirichlet（α &#x3D; 15）非独立同分布数据下评估 ASPFL 的隐私性能。本文将 ASPFL 与典型的集中差分隐私（CDP）和本地差分隐私（LDP）联邦学习方法进行比较，实验结果表明，ASPFL 在性能方面优于其他方法。在 CIFAR-10 数据集上，我们设置 20% 客户端参与，平均测试准确性显著高于 DP-FedAvg、f-DP 和 Wu 等人的方法。与其他方法相比，ASPFL 在 IID 和非 IID 设置下都表现出更高的准确率，同时在达到模型收敛所需的通信轮次方面表现出较低的通信开销，相比 DP-FedAvg 和 f-DP，ASPFL 减少了 40% 的通信轮次。</p>
<h2 id="4-4-参与客户端数量的影响"><a href="#4-4-参与客户端数量的影响" class="headerlink" title="4.4 参与客户端数量的影响"></a>4.4 参与客户端数量的影响</h2><p>在不同参与客户端数量的情况下，对 ASPFL-p 系统的测试结果表明，增加参与客户端数量可以加速收敛并提高最终性能。更多的客户端有助于模型学习更多样化的数据，从而提高泛化能力，同时随着更多客户端对梯度聚合的贡献，生成的梯度更稳定，噪声更小，进而帮助模型更快、更准确地收敛。</p>
<h1 id="5-结论"><a href="#5-结论" class="headerlink" title="5.结论"></a>5.结论</h1><p>本文提出了一种高效的联邦学习框架，能够在保证隐私的前提下优化通信效率。在传输模型更新之前，利用基于每个客户端数据分布的 JS 散度的稀疏剪枝机制进行模型压缩。为了在模型更新中引入隐私保护，我们提出了一种自适应的高斯噪声策略，以实现差分隐私（DP）。通过实验结果中的准确性和通信成本表现可以得出结论，我们的 ASPFL 框架在 CIFAR-10 数据集上表现出稳健的性能和有竞争力的准确率。</p>
<p>从另一个角度来看，大量实验表明，本文所提出的策略具有较强的领域适应性。随着数据多样性和任务复杂性的增加，本文所提出的方法预计能够在准确性和通信开销之间实现更好的平衡。</p>
<h1 id="关键名词解释"><a href="#关键名词解释" class="headerlink" title="关键名词解释"></a>关键名词解释</h1><h2 id="1-边缘计算"><a href="#1-边缘计算" class="headerlink" title="1.边缘计算"></a>1.边缘计算</h2><p>边缘计算是一种分布式计算方式，通过将计算资源和数据存储靠近数据源或用户端来减少延迟和带宽需求。与传统的云计算不同，边缘计算不需要将所有数据都传输到远程数据中心进行处理，而是在靠近设备（例如传感器、摄像头、智能手机）的位置直接处理数据，这使得响应速度更快，更适合需要实时处理的应用。</p>
<p><strong>边缘计算的主要特点</strong><br>低延迟：在数据源附近处理数据，无需长距离数据传输，因此减少了网络延迟。对实时性要求高的应用（如自动驾驶、视频监控等）尤其重要。<br>数据本地化：数据在本地处理，减少了隐私泄露的风险，因为敏感信息不需要传输到远程服务器，有助于数据隐私保护。<br>节省带宽：因为只需要传输处理后的结果，而不是大量的原始数据，边缘计算降低了网络带宽需求，减轻了数据中心的负担。<br>适应性强：边缘计算可以灵活地在分布式网络中进行部署，适合多种场景，如智能家居、工业自动化、智慧城市等。</p>
<p><strong>边缘计算的应用场景</strong><br>自动驾驶：自动驾驶汽车需要实时分析来自摄像头、激光雷达等传感器的数据。边缘计算使得汽车能够在本地做出快速决策。<br>工业物联网（IIoT）：在工厂内，通过边缘计算实时监控设备状态和生产数据，以便及时响应故障。<br>智能城市：交通灯和监控摄像头等设备可以通过边缘计算来分析交通情况、识别异常行为等，提升公共安全和交通效率。<br>智能零售：在零售门店中，边缘计算可以分析摄像头捕捉的顾客行为数据，从而优化商品摆放或提供个性化服务。<br>边缘计算与云计算的关系<br>边缘计算和云计算并不是替代关系，而是相互补充的。边缘计算适合需要实时处理和低延迟的应用，而云计算更适合进行大规模的数据存储和复杂的数据分析。通过将边缘计算与云计算结合，可以在不同场景下提供更高效的数据处理方案。</p>
<h2 id="2-稀疏性剪枝（Sparsity-Pruning）"><a href="#2-稀疏性剪枝（Sparsity-Pruning）" class="headerlink" title="2.稀疏性剪枝（Sparsity Pruning）"></a>2.稀疏性剪枝（Sparsity Pruning）</h2><p>稀疏性剪枝是一种模型压缩技术，减少模型中的冗余参数，以降低通信成本和计算开销。本文采用自适应稀疏性剪枝，生成一个稀疏矩阵来选择重要的模型参数进行传输。通过剪枝，可以减少联邦学习系统中的通信数据量。</p>
<h2 id="3-ASPFL框架（Adaptive-Sparsity-based-Pruning-Federated-Learning）"><a href="#3-ASPFL框架（Adaptive-Sparsity-based-Pruning-Federated-Learning）" class="headerlink" title="3.ASPFL框架（Adaptive Sparsity-based Pruning Federated Learning）"></a>3.ASPFL框架（Adaptive Sparsity-based Pruning Federated Learning）</h2><p>ASPFL是一种自适应稀疏性剪枝的联邦学习框架，结合了差分隐私保护。在ASPFL中，每个客户端在训练完成后使用稀疏矩阵进行模型更新的通道剪枝，然后上传至服务器。服务器会基于估计的敏感度添加自适应的高斯噪声，从而保证隐私。</p>
<h2 id="4-Jensen-Shannon散度（JS-Divergence）"><a href="#4-Jensen-Shannon散度（JS-Divergence）" class="headerlink" title="4.Jensen-Shannon散度（JS Divergence）"></a>4.Jensen-Shannon散度（JS Divergence）</h2><p>Jensen-Shannon散度用于量化各客户端数据的标签分布与均匀分布之间的差异。ASPFL利用JS散度来构建稀疏矩阵，使得模型在不均衡数据分布（Non-IID）下仍能实现高效的学习。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/10/27/20241027/" data-id="cm2tuvies000afw9j1rdt4whs" data-title="20241027论文学习" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-2024.10.15" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/15/2024.10.15/" class="article-date">
  <time class="dt-published" datetime="2024-10-15T08:14:36.000Z" itemprop="datePublished">2024-10-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/15/2024.10.15/">2024.10.15.</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="今天的学习内容"><a href="#今天的学习内容" class="headerlink" title="今天的学习内容"></a>今天的学习内容</h1><p>今天我继续阅读FIGRET-sigcomm2024-1(TE)V2。目前已经阅读至FIGRET部分。</p>
<h1 id="1-论文关键词"><a href="#1-论文关键词" class="headerlink" title="1.论文关键词"></a>1.论文关键词</h1><p>流量工程，广域网，数据中心网络，机器学习</p>
<h1 id="2-TE模型部分"><a href="#2-TE模型部分" class="headerlink" title="2.TE模型部分"></a>2.TE模型部分</h1><h2 id="2-1-概念介绍"><a href="#2-1-概念介绍" class="headerlink" title="2.1 概念介绍"></a>2.1 概念介绍</h2><p><strong>最大链路利用率</strong><br>MLU 是流量工程（TE）优化中的核心指标，表示在网络中使用最多的链路的流量与其容量的比例。MLU越高，网络链路越可能过载，导致丢包、延迟增加和吞吐量下降。FIGRET的目标是最小化MLU。</p>
<p><strong>流量突发</strong><br>在实际网络中，流量通常是动态且不可预测的，某些源-目的对的流量可能突然大幅增长，称为“流量突发”。这些突发事件如果没有预先应对，可能会导致网络拥塞。FIGRET的设计考虑了如何增强对流量突发的鲁棒性。</p>
<p><strong>路径敏感度</strong><br>路径敏感度是用来衡量路径对流量突发的敏感程度。敏感度越高，路径受流量波动的影响越大。因此，降低敏感度可以提高路径的鲁棒性。FIGRET通过约束路径敏感度来控制对流量突发的影响。</p>
<p><strong>期望流量矩阵</strong><br>期望流量矩阵<br>𝐷<sub>𝑒𝑥𝑝𝑒𝑐𝑡</sub>是基于历史数据预测的未来流量需求。虽然预测可能不准确，尤其在流量突发的情况下，但𝐷<sub>𝑒𝑥𝑝𝑒𝑐𝑡</sub>仍是流量工程配置的基础。FIGRET设计旨在通过考虑流量突发的不确定性来应对预测误差。</p>
<p><strong>深度神经网络</strong><br>FIGRET通过深度神经网络（DNN）学习历史流量数据与TE配置之间的映射。DNN可以有效避免显式预测流量矩阵，从而减少计算复杂度，并通过设计特定的损失函数来优化TE配置的性能。</p>
<h2 id="2-2-核心设计思路"><a href="#2-2-核心设计思路" class="headerlink" title="2.2 核心设计思路"></a>2.2 核心设计思路</h2><p><strong>细粒度鲁棒性增强策略</strong></p>
<p>FIGRET的核心思路是对每个源-目的对应用不同的鲁棒性要求。对于流量稳定的源-目的对，放松其鲁棒性要求以提高性能；而对于流量波动较大的源-目的对，严格要求其鲁棒性以应对突发流量。这样做可以实现TE性能在正常流量和突发流量场景下的平衡。</p>
<p><strong>流量突发处理</strong></p>
<p>FIGRET通过定义一个集合Δ来捕获流量突发的不同可能性。在优化TE配置时，FIGRET不仅考虑预测的流量，还加入了突发流量的影响，以确保在最坏情况下仍能提供鲁棒的TE解决方案。</p>
<p><strong>路径敏感度约束</strong></p>
<p>在流量突发情况下，FIGRET通过对路径敏感度施加约束来增强网络的鲁棒性。路径敏感度越低，路径对流量波动的响应越稳定。FIGRET根据每个源-目的对的流量特性，动态调整路径敏感度的上限，以实现细粒度的鲁棒性管理。</p>
<p><strong>端到端方法</strong></p>
<p>FIGRET采用端到端方法，通过深度神经网络（DNN）直接从历史流量数据映射到TE配置，避免了显式流量预测的步骤。与两阶段方法（先预测流量，再求解优化问题）相比，端到端方法能够更好地利用网络拓扑结构，消除上游流量预测和下游网络优化之间的失配。</p>
<p><strong>损失函数设计</strong></p>
<p>FIGRET的损失函数设计基于最大链路利用率（MLU）的最小化和路径敏感度的约束。通过拉格朗日松弛，损失函数分为两个部分：一部分用于最小化MLU，另一部分通过路径敏感度来确保不同源-目的对的细粒度鲁棒性。</p>
<p><strong>深度神经网络架构</strong></p>
<p>FIGRET选择了全连接网络（FCN）作为深度神经网络的架构，因为它能够通过简单的矩阵运算处理TE中的网络拓扑信息。相比于图神经网络（GNN）或卷积神经网络（CNN），全连接网络在计算复杂度和内存占用方面更具优势，尤其适合处理大规模网络的TE问题。</p>
<p><strong>公式</strong><br>公式可参考本链接通过百度网盘分享的图片：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1sOeyCvd-iQO3EjRSqSBZgA">百度网盘分享，提取码：7568</a></p>
<h2 id="2-3-总结"><a href="#2-3-总结" class="headerlink" title="2.3 总结"></a>2.3 总结</h2><p>FIGRET的设计以提高流量工程中的鲁棒性为核心，通过精细化管理不同源-目的对的鲁棒性要求，结合深度学习技术，提供了一个在复杂动态流量条件下表现优越的TE方案。其端到端的设计方法、针对流量突发的敏感度控制、以及基于DNN的损失函数设计，使得FIGRET能够在提升鲁棒性的同时保证较高的TE性能。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/10/15/2024.10.15/" data-id="cm2tuvien0002fw9j3r2e48a3" data-title="2024.10.15." class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-2024.10.14" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/14/2024.10.14/" class="article-date">
  <time class="dt-published" datetime="2024-10-14T08:00:36.000Z" itemprop="datePublished">2024-10-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/14/2024.10.14/">2024.10.14.</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="今天的学习内容"><a href="#今天的学习内容" class="headerlink" title="今天的学习内容"></a>今天的学习内容</h1><p>今天我继续阅读FIGRET-sigcomm2024-1(TE)V2。目前已经阅读至TE模型部分。</p>
<h1 id="1-论文关键词"><a href="#1-论文关键词" class="headerlink" title="1.论文关键词"></a>1.论文关键词</h1><p>流量工程，广域网，数据中心网络，机器学习</p>
<h1 id="2-TE模型部分"><a href="#2-TE模型部分" class="headerlink" title="2.TE模型部分"></a>2.TE模型部分</h1><h2 id="2-1-概念介绍"><a href="#2-1-概念介绍" class="headerlink" title="2.1 概念介绍"></a>2.1 概念介绍</h2><p><strong>网络拓扑（Network Topology）</strong><br>通过图𝐺建模的网络拓扑结构是整个流量工程优化的基础。节点表示交换机或路由器，链路表示节点之间的通信线路，链路的容量决定了流量能够通过的上限。</p>
<p><strong>需求矩阵（Demand Matrix, DM）</strong><br>这是一个 ∣𝑉∣×∣𝑉∣的矩阵，用于表示网络中每一对源-目的节点之间的流量需求。需求矩阵帮助TE模型确定需要转发的流量规模，并为流量分配和路径选择提供依据。</p>
<p><strong>最大链路利用率（MLU, Maximum Link Utilization）</strong><br>MLU 是优化目标中最关键的度量指标，表示网络中单条链路的最大利用率。最小化MLU可以避免网络链路的过载问题，提高网络的整体性能。</p>
<p><strong>TE配置（TE Configuration）</strong><br>TE配置𝑅指定了如何在多个路径之间分配流量。通过为每条路径设置分配比率𝑟<sub>𝑝</sub>，TE配置可以灵活地应对不同流量需求和网络状况的变化。</p>
<p><strong>分配比率（Split Ratio）</strong><br>分配比率𝑟<sub>𝑝</sub>表示从源到目的节点的流量在某条路径上的占比。这一概念使得TE模型可以在多条路径之间分摊流量，达到平衡网络负载的目的。</p>
<p><strong>鲁棒性（Robustness）</strong><br>面对突发流量的不可预测性，TE模型必须具备一定的鲁棒性，能够快速响应和调整。通过考虑预期与非预期流量之间的差异，模型提高了对突发流量的适应能力。</p>
<h2 id="2-2-核心设计思路"><a href="#2-2-核心设计思路" class="headerlink" title="2.2 核心设计思路"></a>2.2 核心设计思路</h2><p><strong>网络拓扑建模</strong><br>网络被建模为图𝐺&#x3D;(𝑉,𝐸,𝑐)，其中𝑉表示节点集，𝐸表示链路（边）集，𝑐表示链路的容量。这种抽象简化了实际网络，将网络中的每个节点和链路的物理特性用数学方式表达，便于后续的分析和优化。</p>
<p><strong>流量需求的表示</strong><br>流量需求通过 需求矩阵（Demand Matrix, DM） 表示，矩阵中的元素指定了从源节点到目的节点的流量需求。这帮助模型明确需要在网络中处理的流量量级和各个源-目的对之间的通信需求。</p>
<p><strong>路径的选择与容量定义</strong><br>每对源-目的对之间可能有多个路径可以选择。路径的容量被定义为该路径上最小容量的链路，确保路径的瓶颈限制能够得到有效考虑。在流量工程中，通过合理选择路径并分配流量，可以平衡链路的负载，防止个别链路过载。</p>
<p><strong>TE配置的定义与流量分配</strong><br>TE配置指定了从源节点到目的节点的流量如何分布在不同的路径上。通过引入分配比率（Split Ratio），模型可以控制流量在各条路径上的分布，从而灵活应对网络的负载情况。</p>
<p><strong>优化目标：最小化最大链路利用率（MLU）</strong><br>核心目标是最小化 最大链路利用率（Maximum Link Utilization, MLU），即尽量降低单条链路的最大负载。这是因为MLU过高时，链路容易过载，导致数据包丢失、延迟增加和整体吞吐量下降。因此，优化模型的首要任务是设计TE配置，使得网络中各条链路的利用率均衡，避免局部拥塞。</p>
<p><strong>不确定流量下的TE配置</strong><br>在实际应用中，流量具有不确定性，且难以完全预测未来流量情况。模型的一个重要设计是基于历史数据来进行TE配置的推导。这种做法帮助模型在流量实际到达之前，预先进行网络配置，并在预测流量的基础上保持低MLU。</p>
<p><strong>处理预期与非预期流量</strong><br>由于突发流量的不可预测性，模型同时考虑了 预期流量（通过历史数据预测）和 非预期流量（突发流量）之间的差异。这种设计使得模型更具鲁棒性，即使面对流量激增的情况，也能快速调整，避免网络过载。</p>
<p><strong>公式</strong><br>公式可参考本链接通过百度网盘分享的图片：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1zwJqzUwwzmV7f25TBk33fg">百度网盘分享，提取码：7568</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/10/14/2024.10.14/" data-id="cm2tuvieo0003fw9j5x1tdx98" data-title="2024.10.14." class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-20240925听会记录" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/25/20240925%E5%90%AC%E4%BC%9A%E8%AE%B0%E5%BD%95/" class="article-date">
  <time class="dt-published" datetime="2024-09-25T14:14:00.000Z" itemprop="datePublished">2024-09-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/25/20240925%E5%90%AC%E4%BC%9A%E8%AE%B0%E5%BD%95/">20240925听会记录</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="会议摘要"><a href="#会议摘要" class="headerlink" title="会议摘要"></a>会议摘要</h1><p>报告将探讨大模型表征空间的特征，展示大模型表征空间对齐的例子，包括多模态表征的对齐、抽象表征的提取以及表征空间的相似性度量。在此基础上，将展示一个新的表征度量利用大模型表征对齐的性质来分析和理解多模态大模型中幻觉现象的来源，解剖大模型的各个模块的贡献。最后通过展示针对商业多模态模型中版权防御的越狱攻击，探讨通过操控表征空间实现安全可控生成的方法，总结在这一研究方向上的结果并展望未来发展。</p>
<h1 id="会议内容——大模型机理分析"><a href="#会议内容——大模型机理分析" class="headerlink" title="会议内容——大模型机理分析"></a>会议内容——大模型机理分析</h1><h2 id="1-大模型表征空间正在对齐"><a href="#1-大模型表征空间正在对齐" class="headerlink" title="1.大模型表征空间正在对齐"></a>1.大模型表征空间正在对齐</h2><p>eg:CLIP模型零样本能力、模型缝合、多模态大模型</p>
<h2 id="2-背景介绍"><a href="#2-背景介绍" class="headerlink" title="2.背景介绍"></a>2.背景介绍</h2><p><strong>模型的幻觉：</strong>模型生成看似可信但不忠实或无意义的内容<br>-忠实性幻觉：生成内容与用户输入矛盾 eg：视觉语言模型幻觉，图文不一致<br>-事实性幻觉：生成内容与现实世界知识相悖</p>
<p>幻觉的评估，图文之间的以执行（基于QA的评测指标，如POPE、MME等）</p>
<p>多模态模型幻觉来自于Visual encoder,LLM,Adaptor</p>
<p><strong>研究方法：</strong>探查（外接分类器）（需要额外参数，效果与训练水平强相关）、无参数对其度量。</p>
<p>线性相关系数：0.75到0.78，而一般只有0.2到0.3，并不是模型越大越好</p>
<p><strong>反思：</strong><br>-表征对齐与模型度量<br>-模型表征的对齐可以作为幻觉的精细度量<br>-模型表征的对齐可以诊断模型</p>
<h2 id="3-大模型表征对齐与商业"><a href="#3-大模型表征对齐与商业" class="headerlink" title="3.大模型表征对齐与商业"></a>3.大模型表征对齐与商业</h2><p>为了避免生成图片的版权纠纷，商业大模型会采用防御机制拒绝生成敏感图片</p>
<p>-可能采用的机制：对齐、关键词屏蔽、生成后检查<br>-方法：自动攻击提示词生成</p>
<p><strong>反思：</strong><br>-表征编辑、基于强化学习的表征编辑<br>-更深入的探索：新的表征对齐度量方法<br>-更实际的应用：在表征空间对表征渐进改进，平衡效果和新能；在多模态结果寻找更合理的算法。</p>
<h1 id="3-会议相关资源"><a href="#3-会议相关资源" class="headerlink" title="3.会议相关资源"></a>3.会议相关资源</h1><p>-<strong>大模型测试结果：</strong><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1OFLeYu0lYvNWet45Fs1M9A">百度网盘分享，提取码：7568</a><br>-<strong>表征对齐推导：</strong><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1XbOE4u-9sZzJajVKrByNVg">百度网盘分享，提取码：7568</a><br>-<strong>无参数对齐度量推导：</strong><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1g9dIHIiYDH-fuH8RrtepbQ">百度网盘分享，提取码：7568</a></p>
<h1 id="4-会议总结"><a href="#4-会议总结" class="headerlink" title="4.会议总结"></a>4.会议总结</h1><p>这是本人第一次使用b站平台收听会议。在这之中，我对模型的幻觉、表征空间等概念有了认识，并会在未来将这当中的部分思路应用在项目之中！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/09/25/20240925%E5%90%AC%E4%BC%9A%E8%AE%B0%E5%BD%95/" data-id="cm2tuvier0007fw9j4e2q598j" data-title="20240925听会记录" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BC%9A%E8%AE%AE%E8%AE%B0%E5%BD%95/" rel="tag">会议记录</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-2024.9.25" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/25/2024.9.25/" class="article-date">
  <time class="dt-published" datetime="2024-09-25T09:40:46.000Z" itemprop="datePublished">2024-09-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/25/2024.9.25/">2024.9.25.</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="今天的学习内容"><a href="#今天的学习内容" class="headerlink" title="今天的学习内容"></a>今天的学习内容</h1><p>今天我继续阅读FIGRET-sigcomm2024-1(TE)V2。目前已经阅读至介绍部分。</p>
<h1 id="1-论文关键词"><a href="#1-论文关键词" class="headerlink" title="1.论文关键词"></a>1.论文关键词</h1><p>流量工程，广域网，数据中心网络，机器学习</p>
<h1 id="2-介绍部分"><a href="#2-介绍部分" class="headerlink" title="2.介绍部分"></a>2.介绍部分</h1><h2 id="2-1-原文重现"><a href="#2-1-原文重现" class="headerlink" title="2.1 原文重现"></a>2.1 原文重现</h2><p>随着网络流量的指数级增长，数据中心网络和广域网（WAN）越来越依赖流量工程（TE）来优化网络性能。TE 通常通过软件定义网络（SDN）的集中控制器实现，定期解决优化问题，以有效地将流量分配到网络路径上，然后将这些解决方案转化为路由器配置。</p>
<p>TE 中的一个主要挑战是管理突发流量。由于中央控制器在收集流量需求、计算新的 TE 解决方案以及更新转发规则时引入的延迟，TE 系统通常需要在实际流量到达之前，基于历史数据预先计算网络配置。然而，实际网络流量本质上的动态性和不可预测性给预测带来了巨大的困难。如果对流量突发准备不足，可能导致严重的网络拥塞，引发延迟增加、数据包丢失率上升以及网络吞吐量下降。因此，增强应对意外流量突发的鲁棒性至关重要。</p>
<p>现有的基于流量突发的 TE 方案通常是在牺牲常规网络性能的情况下处理流量突发。例如，盲目路由法优化了所有流量需求的最坏情况，尽管这种方法提供了最高级别的鲁棒性以应对流量突发，但它往往会导致非突发流量模式下的性能极差，而非突发流量模式通常占据大部分时间。作为改进，Cope 聚焦于优化预测的流量需求，同时提供最坏情况下的性能保证。然而，提供这样的最坏情况保证可能会显得过度，因为某些流量模式可能永远不会发生。此外，COPE 的计算复杂性也很高。因此，提出了一类新的 TE 方法，这些方法不再对整个流量模式空间提供保证，而是通过直接限制不同路径的路由权重来增强鲁棒性。例如，COUDER 引入了路径敏感性指标来评估突发流量对每条路径的影响，并通过最小化所有路径的最大敏感性来增强鲁棒性。同样，谷歌的光学数据中心在 TE 中采用了一种对冲机制，通过将路径敏感性限制在预定的上限之下来增强鲁棒性。然而，这些方法可能会影响非突发流量场景下的 TE 性能，因为它们会强制将流量分散到多条（可能更长的）路径上，而不是选择最佳路径，即使某些源-目的对之间的流量是稳定的。</p>
<p>现有方法的局限性可归因于它们对流量突发的统一处理。在实际中，不同源-目的对的网络流量表现出不同的特征。有些对可能经常遇到流量突发，而另一些则可能保持显著的稳定性。对于持续稳定的流量，优先考虑鲁棒性是不必要的，甚至可能会损害性能。</p>
<p>基于这一观察，我们设计了 FIGRET（一种细粒度的增强鲁棒性的流量工程方案）。FIGRET 的关键见解在于，根据每个源-目的对的流量特征定制鲁棒性增强策略。对于流量稳定的源-目的对，FIGRET 采用较为宽松的鲁棒性要求，而对于容易突发的源-目的对，则施加更严格的要求。类似于 COUDER，FIGRET 也使用路径敏感性指标来增强对流量突发的鲁棒性。除此之外，FIGRET 根据网络拓扑和不同源-目的对的流量特征定制路径敏感性约束。这一策略使 FIGRET 能够实现细粒度的鲁棒性增强，并在常规和突发流量场景下的 TE 性能之间取得良好平衡。</p>
<p>提出 FIGRET 方案后，接下来的挑战是如何有效地计算 TE 解决方案。乍一看，FIGRET 的方案可以通过线性规划直接解决。然而，这种方法有两个缺点。首先，直接求解 FIGRET 需要一个预测的流量矩阵。然而，由于存在高度突发的源-目的对，找到一个合适的流量预测是困难的。其次，线性规划的计算复杂度较高，可能无法扩展到大型网络。为了解决这些问题，FIGRET 利用深度神经网络加速 TE 计算。类似于 DOTE，FIGRET 直接将历史流量模式映射到路由权重配置，从而消除了对流量预测的需求。为了处理路径敏感性约束，FIGRET 在其损失函数中添加了一个额外的项，以捕捉定制的鲁棒性需求。</p>
<p>我们对 FIGRET 进行了全面的评估。本次评估利用了公开的广域网数据集，以及数据中心 PoD 级和 ToR 级的拓扑和流量数据。这些数据涵盖了从几十个到几百个节点的拓扑结构，其相应的流量数据表现出多种特征，包括低、中、高突发性的流量模式。通过我们的评估，我们发现 FIGRET 在各种拓扑中始终提供高质量的 TE 解决方案。与谷歌生产数据中心中当前的 TE 系统相比，FIGRET 在不同拓扑上平均将最大链路利用率（MLU）减少了 9%-34%，并将解决方案生成速度提高了 35 至 1800 倍。与当前最先进的基于深度学习的 TE 系统 DOTE 相比，FIGRET 在两种具有突发流量数据的拓扑中取得了显著的改进。它分别减少了平均最大链路利用率 4.5% 和 5.3%，同时减少了因流量突发导致的严重拥塞事件的发生率，分别下降了 41% 和 53.9%。同时，在具有稳定流量数据的拓扑中，FIGRET 的性能至少与 DOTE 相当，尽管它额外考虑了鲁棒性。最后，我们对 FIGRET 的卓越性能进行了数值解释。我们的代码已在 [1] 中提供。</p>
<p>本研究未提出任何伦理问题。</p>
<h2 id="2-2-核心总结"><a href="#2-2-核心总结" class="headerlink" title="2.2 核心总结"></a>2.2 核心总结</h2><p>FIGRET的关键在于对于是否容易突发的源-目的对进行分类讨论，从而定制增强鲁棒性，并在各类场景下TE性能取得良好平衡。而对于计算解决方案时，不能直接采用线性规划，应当采用深度神经网络加速TE计算，并在损失函数中加入额外想处理路径敏感性约束。</p>
<h1 id="3-动机与关键见解"><a href="#3-动机与关键见解" class="headerlink" title="3.动机与关键见解"></a>3.动机与关键见解</h1><h2 id="3-1-原文重现"><a href="#3-1-原文重现" class="headerlink" title="3.1 原文重现"></a>3.1 原文重现</h2><p><strong>3.1.1 管理突发流量的必要性</strong><br>流量工程 (TE) 已在广域网（例如 Google 的 B4 和 Microsoft 的 SWAN）及数据中心（例如 Google 的光学数据中心网络）中采用，以提高网络利用率并防止网络拥塞。</p>
<p>为了说明在 TE 中管理突发流量的必要性，我们对突发流量对网络性能的影响进行了分析。我们在这项研究中实施了两种策略：1）“无对冲”策略，该策略使用当前的流量矩阵来决定下一个时间间隔的 TE 配置，但不采取任何管理突发的措施；2）“对冲”策略，该策略同样使用当前的流量矩阵配置下一个时间间隔，但引入了 Google 在其 Jupiter 数据中心网络中使用的对冲机制。对冲机制的基本原理是将流量分散到多条路径上，以防止突发流量对某一条路径产生过大的影响。我们在 GEANT WAN 和 Meta 数据中心的 PoD&#x2F;ToR 级直接连接拓扑上进行评估，并使用收集到的流量数据进行实验。我们的结果包括：</p>
<p>-对网络波动的性能敏感性：从 GEANT WAN 到 PoD 级数据中心网络，再到 ToR 级数据中心网络，流量变得更加不稳定，“无对冲”策略的性能波动性也逐渐增大。<br>-抗突发的必要性：在广域网和数据中心网络中，如果不采取抗突发策略，“无对冲”策略下 MLU 峰值更高，表明网络在突发时容易出现拥塞。<br>-抗突发策略的性能折中：在“无对冲”策略中，MLU 曲线的峰值较高，表示突发时的性能下降，而谷值较低，表示在非突发情况下的性能提升。相比之下，“对冲”策略在非突发情况下的谷值不会像“无对冲”策略那样低，因为它强制大量流量通过非最优路径。<br>总结：在 TE 中管理突发流量是必要的，但抗突发策略往往会损害非突发场景下的性能。因此，我们需要一种能够有效管理突发流量，同时尽量减少对非突发场景性能影响的 TE 方法。</p>
<p><strong>3.2.2 流量特征的多样性</strong><br>虽然突发流量确实会发生，但不同源-目的对之间的突发程度各不相同。为了说明这一点，我们对各种生产网络中的流量特征进行了分析。结果显示，无论是在 WAN 还是在 PoD 级和 ToR 级数据中心网络中，不同源-目的对的流量需求表现出明显的差异。</p>
<p>对于不同源-目的对的流量需求方差，方差越大，源-目的对的流量越不稳定。结果表明，不同的源-目的对需要不同的 TE 方案。如果对所有源-目的对采用统一的策略，TE 方案可能会在非突发场景中表现欠佳，或者牺牲应对突发场景的能力。因此，充分利用 TE 中的流量特征多样性对于更好地平衡突发和非突发场景的性能折中至关重要。</p>
<p><strong>3.2.3 深入分析性能折中</strong><br>TE 中的折中困境：为了说明 TE 中的折中困境，我们在提供了一个说明性示例。在这个网络中，有三个流量需求：A→B，A→C，B→C。在正常情况下，三个流量需求的大小均为1。然而，在三个不同的突发场景中，A→B，A→C，B→C 的流量需求分别增加到 4。</p>
<p>TE 方案1：假设所有流量都不是突发的，只优化正常情况。在正常情况下，其最大链路利用率（MLU）为 0.5。但当任何突发情况发生时，MLU 增加到 2。</p>
<p>TE 方案2：假设所有流量都可能发生突发事件，通过将流量分散到不同的路径上增强鲁棒性。在处理正常情况时，MLU 为 0.75，而在处理突发情况下，MLU 为 1.5。相比 TE 方案1，TE 方案2 在处理突发流量时表现更佳，但正常性能有所下降。</p>
<p>TE 方案3：专门针对 B→C 的突发情况，选择两条路径为 B→C 提供流量服务，而 A→B 和 A→C 选择直连路径。在正常情况下，其 MLU 为 0.6875。在处理突发情况1或2时，MLU 为 2.1875；处理突发情况3时，MLU 为 1.25。尽管在处理突发情况1&#x2F;2时，TE 方案3 的鲁棒性不如 TE 方案2，但在正常情况和突发情况3下的性能优于 TE 方案2。</p>
<h2 id="3-2-核心总结"><a href="#3-2-核心总结" class="headerlink" title="3.2 核心总结"></a>3.2 核心总结</h2><p>这部分主要展示的是模拟测试的思路，据此可以得知三种方案皆有适应的场景，需要通过为每个源-目的对量身定制不同的鲁棒性要求，可以实现更有效的性能折中。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/09/25/2024.9.25/" data-id="cm2tuvieq0006fw9j9zgu8qxy" data-title="2024.9.25." class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-2024.9.24" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/24/2024.9.24/" class="article-date">
  <time class="dt-published" datetime="2024-09-24T15:40:29.000Z" itemprop="datePublished">2024-09-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/24/2024.9.24/">2024.9.24.</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="今天的学习内容"><a href="#今天的学习内容" class="headerlink" title="今天的学习内容"></a>今天的学习内容</h1><p>今天我阅读了FIGRET-sigcomm2024-1(TE)V2。由于白天在处理计算机系统导论的实验内容，傍晚事先搭建了博客，目前只阅读了摘要部分。</p>
<h2 id="1-摘要部分"><a href="#1-摘要部分" class="headerlink" title="1. 摘要部分"></a>1. 摘要部分</h2><p>流量工程 (TE) 对于提升网络性能和可靠性至关重要。TE 中的一个关键挑战是管理突发的流量激增。现有的TE方案要么无法处理流量突发，要么对所有流量突发情况采取统一防御措施，因此难以在常规场景性能和突发场景性能之间取得平衡。为了解决这一问题，我们提出了FIGRET，一种细粒度的增强鲁棒性的流量工程方案。FIGRET 提供了一种新颖的TE方法，根据不同源-目的对的流量特征，定制不同级别的鲁棒性增强。通过利用基于流量突发感知的损失函数和深度学习技术，FIGRET能够高效生成高质量的TE解决方案。我们对现实生产网络（包括广域网和数据中心）的评估显示，FIGRET 显著优于现有的 TE 方案。与谷歌 Jupiter 数据中心网络中当前部署的 TE 方案相比，FIGRET 将最大链路利用率平均减少了 9%-34%，并将解决方案生成速度提升了 35 到 1800 倍。与 DOTE（一种基于深度学习的最先进的 TE 方法）相比，FIGRET 在高流量动态拓扑中大幅降低了由流量突发引发的严重拥塞事件的发生率，减少幅度在 41%-53.9% 之间。</p>
<h2 id="2-重要概念1——流量工程"><a href="#2-重要概念1——流量工程" class="headerlink" title="2. 重要概念1——流量工程"></a>2. 重要概念1——流量工程</h2><p>流量工程（Traffic Engineering, 简称 TE）是网络管理中的一个重要领域，旨在通过优化网络资源的使用来提高网络性能、可用性和可靠性。其核心目标是有效地管理网络流量，使其以最佳的方式通过网络，从而避免拥塞、减少延迟、最大化链路的利用率，以及确保更高的服务质量 (QoS)。流量工程通常应用在数据中心网络、广域网（WAN）和软件定义网络（SDN）等环境中。<br><strong>流量工程的关键概念：</strong><br>-流量优化：流量工程的主要任务是根据不同的网络流量需求，计算出最佳的路由方案，使得流量在网络中以最有效的方式进行传输。例如，通过选择不同的路径，将流量均衡分布到多条网络链路上，避免某些链路超载。<br>-最大链路利用率（MLU）：MLU 是流量工程中常用的指标，表示网络中最繁忙链路的负载情况。降低 MLU 可以减少网络拥塞和提高整体网络的效率。<br>-流量突发：在实际网络中，流量可能会出现突然激增的现象，这种突发流量可能导致网络拥塞和性能下降。流量工程需要考虑如何应对这些突发事件，增强网络的鲁棒性，确保在突发情况下网络仍能正常工作。<br>-集中式控制：在现代网络（如软件定义网络，SDN）中，流量工程通常通过一个集中式控制器来实现。控制器根据当前的网络状态（如流量矩阵、链路利用情况等），计算出优化的流量路由策略，并将其下发到各个路由器或交换机。<br>-动态适应：由于网络流量具有动态和不可预测性，流量工程不仅需要根据历史数据进行预测，还需要快速响应实际发生的流量变化。这使得实时性和响应速度在 TE 中显得尤为重要。<br><strong>常见的流量工程方法：</strong><br>-最短路径路由：这是最基本的流量路由方式，流量被引导通过从源到目的地的最短路径。然而，这种方法无法解决链路过载的问题。<br>-多路径路由：为避免网络中某条路径拥塞，流量工程会将流量分散到多条路径上，特别是在流量突发或网络故障的情况下。<br>-深度学习&#x2F;机器学习驱动的流量工程：近年来，随着网络流量模式的复杂性增加，基于深度学习的流量工程方案越来越多，利用历史流量数据来预测未来的流量，并生成相应的优化路由配置。</p>
<p>总之，流量工程的核心目标是平衡网络资源的利用和网络性能之间的关系，确保网络能够在不同负载条件下保持高效和稳定的运行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/09/24/2024.9.24/" data-id="cm2tuvieq0005fw9j05v93pqy" data-title="2024.9.24." class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-markdown格式初学" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/24/markdown%E6%A0%BC%E5%BC%8F%E5%88%9D%E5%AD%A6/" class="article-date">
  <time class="dt-published" datetime="2024-09-24T15:03:39.000Z" itemprop="datePublished">2024-09-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/24/markdown%E6%A0%BC%E5%BC%8F%E5%88%9D%E5%AD%A6/">markdown格式初学</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="今天的学习内容"><a href="#今天的学习内容" class="headerlink" title="今天的学习内容"></a>今天的学习内容</h1><p>今天我学习了如何使用 Hexo 来创建博客，并将其部署到 GitHub Pages 上。以下是一些我学习到的重要内容：</p>
<h2 id="1-Hexo-的基本操作"><a href="#1-Hexo-的基本操作" class="headerlink" title="1. Hexo 的基本操作"></a>1. Hexo 的基本操作</h2><ul>
<li><strong>创建新文章</strong>：使用 <code>hexo new &lt;title&gt;</code> 来创建新文章。</li>
<li><strong>生成静态文件</strong>：使用 <code>hexo generate</code> 来生成静态文件。</li>
<li><strong>本地预览</strong>：使用 <code>hexo server</code> 启动本地服务器进行预览。</li>
</ul>
<h2 id="2-Markdown-语法学习"><a href="#2-Markdown-语法学习" class="headerlink" title="2. Markdown 语法学习"></a>2. Markdown 语法学习</h2><p>Markdown 语法是一种简单易学的标记语言，常用于编写文档和博客内容。以下是我学习到的一些常用 Markdown 语法：</p>
<h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><ul>
<li>这是一个无序列表项。</li>
<li>这是另一个无序列表项。</li>
</ul>
<ol>
<li>这是一个有序列表项。</li>
<li>这是另一个有序列表项。</li>
</ol>
<h3 id="链接和图片"><a href="#链接和图片" class="headerlink" title="链接和图片"></a>链接和图片</h3><ul>
<li>这是一个链接：<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo 官方网站</a></li>
<li>这是一个图片： <img src="https://hexo.io/logo.svg" alt="Hexo Logo"></li>
</ul>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><blockquote>
<p>这是一个引用段落，可以用于引用其他文本或标注重要信息。</p>
</blockquote>
<h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><pre><code class="python">print(&quot;Hello, Hexo!&quot;)

console.log(&quot;Hello, Hexo!&quot;);
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seer666.github.io/2024/09/24/markdown%E6%A0%BC%E5%BC%8F%E5%88%9D%E5%AD%A6/" data-id="cm2tuviet000ffw9j6a09fhu5" data-title="markdown格式初学" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/markdown%E8%AF%AD%E6%B3%95/" rel="tag">markdown语法</a></li></ul>

    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar" >

  <!-- 在侧边栏顶部添加个人信息框 -->
  <div class="author-info-box">
    <a href="https://github.com/SEER666" target="_blank">
      <img src="https://avatars.githubusercontent.com/u/126209991?v=4" alt="GitHub Avatar" class="author-avatar">
    </a>
    <div class="author-details">
      <h3>SEER</h3>
      <div class="author-stats">
        <div class="stat-item">
          <span class="stat-label">文档</span>
          <span class="stat-number">8</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">标签</span>
          <span class="stat-number">4</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">分类</span>
          <span class="stat-number">0</span>
        </div>
      </div>
    </div>
  </div>

  <!-- 插入网易云音乐播放器外链 -->
  <div id="music-player">
    <iframe id="music-iframe" frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=2114626833&auto=1&height=66"></iframe>
  </div>

  <!-- 渲染现有的 widgets -->
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSAPP/" rel="tag">CSAPP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown%E8%AF%AD%E6%B3%95/" rel="tag">markdown语法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%9A%E8%AE%AE%E8%AE%B0%E5%BD%95/" rel="tag">会议记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CSAPP/" style="font-size: 10px;">CSAPP</a> <a href="/tags/markdown%E8%AF%AD%E6%B3%95/" style="font-size: 10px;">markdown语法</a> <a href="/tags/%E4%BC%9A%E8%AE%AE%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">会议记录</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 20px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/28/20241028/">20241028-CSAPP课本阅读</a>
          </li>
        
          <li>
            <a href="/2024/10/27/20241027/">20241027论文学习</a>
          </li>
        
          <li>
            <a href="/2024/10/15/2024.10.15/">2024.10.15.</a>
          </li>
        
          <li>
            <a href="/2024/10/14/2024.10.14/">2024.10.14.</a>
          </li>
        
          <li>
            <a href="/2024/09/25/20240925%E5%90%AC%E4%BC%9A%E8%AE%B0%E5%BD%95/">20240925听会记录</a>
          </li>
        
      </ul>
    </div>
  </div>

  

  <!-- 直接在 sidebar.ejs 文件中嵌入样式 -->
  <style>
    /* 个人信息框的样式 */
    .author-info-box {
      max-width: 100%;
      padding: 20px;
      background-color: #f9f9f9;
      border-radius: 10px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      text-align: center;
      margin-bottom: 20px;
    }

    .author-avatar {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      margin-bottom: 10px;
    }

    .author-details h3 {
      margin: 0;
      font-size: 18px;
      color: #333;
    }

    /* 美化统计信息 */
    .author-stats {
      display: flex;
      justify-content: space-around;
      margin-top: 15px;
    }

    .stat-item {
      text-align: center;
    }

    .stat-label {
      font-size: 14px;
      font-weight: 600;
      color: #555;
      display: block;
    }

    .stat-number {
      font-size: 22px;
      font-weight: bold;
      color: #007bff;
      margin-top: 5px;
    }

    /* 网易云音乐播放器的样式 */
    #music-player {
      margin-top: 20px; /* 播放器与上方内容的间距 */
      text-align: center; /* 播放器居中 */
    }

    #music-player iframe {
      width: 100%; /* 自适应宽度 */
      height: auto; /* 自动调整高度 */
    }
  </style>
</aside>

        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 [object Object]<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>

</footer>



    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>